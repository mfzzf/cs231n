{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5c8ec",
   "metadata": {
    "id": "62b5c8ec"
   },
   "outputs": [],
   "source": [
    "# This mounts your Google Drive to the Colab VM.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
    "# assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
    "FOLDERNAME = 'cs231n/assignments/assignment1/'\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# Now that we've mounted your Drive, this ensures that\n",
    "# the Python interpreter of the Colab VM can load\n",
    "# python files from within it.\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# This downloads the CIFAR-10 dataset to your Drive\n",
    "# if it doesn't already exist.\n",
    "%cd /content/drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n",
    "!bash get_datasets.sh\n",
    "%cd /content/drive/My\\ Drive/$FOLDERNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0791de1b",
   "metadata": {
    "tags": [
     "pdf-title"
    ],
    "id": "0791de1b"
   },
   "source": "# 图像特征练习\n*请完成并提交这份完整的作业工作表（包括输出和任何工作表之外的辅助代码）。更多详情请查看课程网站上的[作业页面](http://vision.stanford.edu/teaching/cs231n/assignments.html)。*\n\n我们可以看到，通过在输入图像的像素上训练线性分类器，我们可以在图像分类任务上获得合理的性能。在这个练习中，我们将证明通过在从原始像素计算的特征上训练线性分类器，我们可以提高分类性能。\n\n你在这个练习中的所有工作都将在这个 notebook 中完成。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e23d75",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ],
    "id": "86e23d75"
   },
   "outputs": [],
   "source": "import random\nimport numpy as np\nfrom cs231n.data_utils import load_CIFAR10\nimport matplotlib.pyplot as plt\n\n\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 8.0) # 设置绘图的默认大小\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n\n# 用于自动重新加载外部模块\n# 参见 http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n%load_ext autoreload\n%autoreload 2"
  },
  {
   "cell_type": "markdown",
   "id": "edcba4a5",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ],
    "id": "edcba4a5"
   },
   "source": "## 加载数据\n与之前的练习类似，我们将从磁盘加载 CIFAR-10 数据。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44caba8f",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ],
    "id": "44caba8f"
   },
   "outputs": [],
   "source": "from cs231n.features import color_histogram_hsv, hog_feature\n\ndef get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n    # 加载原始 CIFAR-10 数据\n    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n\n    # 清理变量以防止多次加载数据（这可能导致内存问题）\n    try:\n       del X_train, y_train\n       del X_test, y_test\n       print('清除之前加载的数据。')\n    except:\n       pass\n\n    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n\n    # 对数据进行子采样\n    mask = list(range(num_training, num_training + num_validation))\n    X_val = X_train[mask]\n    y_val = y_train[mask]\n    mask = list(range(num_training))\n    X_train = X_train[mask]\n    y_train = y_train[mask]\n    mask = list(range(num_test))\n    X_test = X_test[mask]\n    y_test = y_test[mask]\n\n    return X_train, y_train, X_val, y_val, X_test, y_test\n\nX_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()"
  },
  {
   "cell_type": "markdown",
   "id": "37e4b3f6",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ],
    "id": "37e4b3f6"
   },
   "source": "## 提取特征\n对于每张图像，我们将计算一个定向梯度直方图（HOG）以及一个使用 HSV 色彩空间中色相通道的色彩直方图。我们通过连接\nHOG 和色彩直方图特征向量为每张图像形成最终的特征向量。\n\n粗略地说，HOG 应该捕获图像的纹理而忽略色彩信息，而色彩直方图表示输入图像的色彩而忽略纹理。因此，我们期望两者一起使用比单独使用任何一种效果更好。验证这一假设对你的兴趣来说是一个很好的尝试。\n\n`hog_feature` 和 `color_histogram_hsv` 函数都在单张图像上操作，并返回该图像的特征向量。extract_features\n函数接收一组图像和一个特征函数列表，并评估\n每个特征函数在每张图像上，将结果存储在一个矩阵中，其中\n每列是单张图像的所有特征向量的连接。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7341d6c7",
   "metadata": {
    "scrolled": true,
    "tags": [
     "pdf-ignore"
    ],
    "id": "7341d6c7"
   },
   "outputs": [],
   "source": "from cs231n.features import *\n\n# num_color_bins = 10 # 色彩直方图中的 bin 数量\nnum_color_bins = 25 # 色彩直方图中的 bin 数量\nfeature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=num_color_bins)]\nX_train_feats = extract_features(X_train, feature_fns, verbose=True)\nX_val_feats = extract_features(X_val, feature_fns)\nX_test_feats = extract_features(X_test, feature_fns)\n\n# 预处理：减去平均特征\nmean_feat = np.mean(X_train_feats, axis=0, keepdims=True)\nX_train_feats -= mean_feat\nX_val_feats -= mean_feat\nX_test_feats -= mean_feat\n\n# 预处理：除以标准差。这确保每个特征\n# 大致具有相同的尺度。\nstd_feat = np.std(X_train_feats, axis=0, keepdims=True)\nX_train_feats /= std_feat\nX_val_feats /= std_feat\nX_test_feats /= std_feat\n\n# 预处理：添加偏置维度\nX_train_feats = np.hstack([X_train_feats, np.ones((X_train_feats.shape[0], 1))])\nX_val_feats = np.hstack([X_val_feats, np.ones((X_val_feats.shape[0], 1))])\nX_test_feats = np.hstack([X_test_feats, np.ones((X_test_feats.shape[0], 1))])"
  },
  {
   "cell_type": "markdown",
   "id": "684ded7b",
   "metadata": {
    "id": "684ded7b"
   },
   "source": "## 在特征上训练 Softmax 分类器\n使用作业前面开发的 Softmax 代码，在上面提取的特征之上训练 Softmax 分类器；这应该比直接在原始像素上训练它们获得更好的结果。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abaf16c",
   "metadata": {
    "tags": [
     "code"
    ],
    "id": "9abaf16c"
   },
   "outputs": [],
   "source": "# 使用验证集来调整学习率和正则化强度\n\nfrom cs231n.classifiers.linear_classifier import Softmax\n\nlearning_rates = [1e-7, 1e-6]\nregularization_strengths = [5e5, 5e6]\n\nresults = {}\nbest_val = -1\nbest_softmax = None\n\n################################################################################\n# TODO:                                                                        #\n# 使用验证集设置学习率和正则化强度。这应该与 Softmax 的验证相同；保存   #\n# 最佳训练分类器于 best_softmax。如果你仔细调整模型，                     #\n# 你应该能够在验证集上获得超过 0.42 的准确率。                               #\n################################################################################\n\n\n# 打印结果。\nfor lr, reg in sorted(results):\n    train_accuracy, val_accuracy = results[(lr, reg)]\n    print('lr %e reg %e 训练准确率: %f 验证准确率: %f' % (\n                lr, reg, train_accuracy, val_accuracy))\n\nprint('最佳验证准确率: %f' % best_val)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54135a4",
   "metadata": {
    "test": "svm_test_accuracy",
    "id": "f54135a4"
   },
   "outputs": [],
   "source": "# 评估你训练好的 Softmax 在测试集上：你应该至少得到 0.42\ny_test_pred = best_softmax.predict(X_test_feats)\ntest_accuracy = np.mean(y_test == y_test_pred)\nprint(test_accuracy)"
  },
  {
   "cell_type": "code",
   "source": "# 保存最佳 softmax 模型\nbest_softmax.save(\"best_softmax_features.npy\")",
   "metadata": {
    "id": "5i2oz_jdndHL"
   },
   "id": "5i2oz_jdndHL",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e879145a",
   "metadata": {
    "id": "e879145a"
   },
   "outputs": [],
   "source": "# 获得算法如何工作的直觉的一个重要方式是\n# 可视化它犯的错误。在这个可视化中，我们显示我们当前系统错误分类的图像示例。第一列\n# 显示我们系统标记为\"plane\"但其真实标签不是\"plane\"的图像。\n\nexamples_per_class = 8\nclasses = ['飞机', '汽车', '鸟', '猫', '鹿', '狗', '青蛙', '马', '船', '卡车']\nfor cls, cls_name in enumerate(classes):\n    idxs = np.where((y_test != cls) & (y_test_pred == cls))[0]\n    idxs = np.random.choice(idxs, examples_per_class, replace=False)\n    for i, idx in enumerate(idxs):\n        plt.subplot(examples_per_class, len(classes), i * len(classes) + cls + 1)\n        plt.imshow(X_test[idx].astype('uint8'))\n        plt.axis('off')\n        if i == 0:\n            plt.title(cls_name)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "a70bdb48",
   "metadata": {
    "tags": [
     "pdf-inline"
    ],
    "id": "a70bdb48"
   },
   "source": "### 内联问题 1：\n描述你看到的错误分类结果。有道理吗？\n\n\n$\\color{blue}{\\textit 你的答案：}$\n\n\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "4fd2d201",
   "metadata": {
    "id": "4fd2d201"
   },
   "source": "## 在图像特征上的神经网络\n在这个作业的前面部分，我们看到在原始像素上训练两层神经网络比在原始像素上的线性分类器获得更好的分类性能。在这个 notebook 中，我们看到在图像特征上的线性分类器比在原始像素上的线性分类器表现更好。\n\n为了完整起见，我们也应该尝试在图像特征上训练神经网络。这种方法应该优于所有以前的方法：你应该很容易在测试集上获得超过 55% 的分类准确率；我们的最佳模型获得大约 60% 的分类准确率。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690a1fa",
   "metadata": {
    "tags": [
     "pdf-ignore"
    ],
    "id": "f690a1fa"
   },
   "outputs": [],
   "source": "# 预处理：移除偏置维度\n# 确保只运行一次此单元格\nprint(X_train_feats.shape)\nX_train_feats = X_train_feats[:, :-1]\nX_val_feats = X_val_feats[:, :-1]\nX_test_feats = X_test_feats[:, :-1]\n\nprint(X_train_feats.shape)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f914d6",
   "metadata": {
    "tags": [
     "code"
    ],
    "id": "30f914d6"
   },
   "outputs": [],
   "source": "from cs231n.classifiers.fc_net import TwoLayerNet\nfrom cs231n.solver import Solver\n\ninput_dim = X_train_feats.shape[1]\nhidden_dim = 500\nnum_classes = 10\n\ndata = {\n    'X_train': X_train_feats,\n    'y_train': y_train,\n    'X_val': X_val_feats,\n    'y_val': y_val,\n    'X_test': X_test_feats,\n    'y_test': y_test,\n}\n\nnet = TwoLayerNet(input_dim, hidden_dim, num_classes)\nbest_net = None\n\n################################################################################\n# TODO: 在图像特征上训练两层神经网络。你可能想要像之前部分一样进行各种参数的交叉验证。将你最好的模型存储在 best_net 变量中。 #\n################################################################################"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54573a5e",
   "metadata": {
    "test": "nn_test_accuracy",
    "id": "54573a5e"
   },
   "outputs": [],
   "source": "# 运行你最好的神经网络分类器在测试集上。你应该能够\n# 得到超过 58% 的准确率。通过仔细调整，也有可能会得到 >60% 的准确率。\n\ny_test_pred = np.argmax(best_net.loss(data['X_test']), axis=1)\ntest_acc = (y_test_pred == data['y_test']).mean()\nprint(test_acc)"
  },
  {
   "cell_type": "code",
   "source": "# 保存最佳模型\nbest_net.save(\"best_two_layer_net_features.npy\")",
   "metadata": {
    "id": "JgC8wNQijcA9"
   },
   "id": "JgC8wNQijcA9",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "96PFBsXX3xbz"
   },
   "id": "96PFBsXX3xbz",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}