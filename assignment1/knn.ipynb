{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f777ad2",
   "metadata": {
    "id": "1f777ad2"
   },
   "outputs": [],
   "source": [
    "# # This mounts your Google Drive to the Colab VM.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
    "# # assignment folder, e.g. 'cs231n/assignments/assignment1/'\n",
    "# FOLDERNAME = 'cs231n/assignments/assignment1/'\n",
    "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# # Now that we've mounted your Drive, this ensures that\n",
    "# # the Python interpreter of the Colab VM can load\n",
    "# # python files from within it.\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# # This downloads the CIFAR-10 dataset to your Drive\n",
    "# # if it doesn't already exist.\n",
    "# %cd /content/drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n",
    "# !bash get_datasets.sh\n",
    "# %cd /content/drive/My\\ Drive/$FOLDERNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e477f1",
   "metadata": {
    "id": "14e477f1",
    "tags": [
     "pdf-title"
    ]
   },
   "source": "# k-近邻算法 (kNN) 练习\n\n*请完成并提交这份完整的作业工作表（包括输出和任何工作表之外的辅助代码）。更多详情请查看课程网站上的[作业页面](http://vision.stanford.edu/teaching/cs231n/assignments.html)。*\n\nkNN 分类器包含两个阶段：\n\n- 在训练期间，分类器接收训练数据并简单地记住它\n- 在测试期间，kNN 通过与所有训练图像进行比较并将 k 个最相似的训练样本的标签进行传递来分类每个测试图像\n- k 的值通过交叉验证确定\n\n在这个练习中，你将实现这些步骤并理解基本的图像分类流程、交叉验证，以及提高编写高效、向量化代码的熟练度。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2960b2e8",
   "metadata": {
    "id": "2960b2e8",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": "# 这段代码为notebook环境进行了一些必要的设置和初始化。\n\nimport random\nimport numpy as np\nfrom cs231n.data_utils import load_CIFAR10\nimport matplotlib.pyplot as plt\n\n# 让matplotlib生成的图像直接显示在notebook内，而不是弹出新窗口\n%matplotlib inline\nplt.rcParams['figure.figsize'] = (10.0, 8.0)  # 设置绘图区的默认大小\nplt.rcParams['image.interpolation'] = 'nearest' # 显示图片时最近邻插值\nplt.rcParams['image.cmap'] = 'gray'            # 设置默认的灰度色表\n\n# 下面两行代码可以让notebook里的外部python模块（比如你自己写的代码文件）代码发生变动时自动重载\n%load_ext autoreload\n%autoreload 2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1123717",
   "metadata": {
    "id": "e1123717",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": "# 加载原始 CIFAR-10 数据。\ncifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n\n# 清理变量以防止多次加载数据（可能导致内存问题）\ntry:\n   del X_train, y_train\n   del X_test, y_test\n   print('清除之前加载的数据。')\nexcept:\n   pass\n\nX_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n\n# 作为健全性检查，我们打印出训练和测试数据的大小。\nprint('训练数据维度: ', X_train.shape)\nprint('训练标签维度: ', y_train.shape)\nprint('测试数据维度: ', X_test.shape)\nprint('测试标签维度: ', y_test.shape)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76457c5",
   "metadata": {
    "id": "f76457c5",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": "# 可视化数据集中的一些示例。\n# 我们展示来自每个类别的几个训练图像示例。\nclasses = ['飞机', '汽车', '鸟', '猫', '鹿', '狗', '青蛙', '马', '船', '卡车']\nnum_classes = len(classes)\nsamples_per_class = 7\nfor y, cls in enumerate(classes):\n    idxs = np.flatnonzero(y_train == y)\n    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n    for i, idx in enumerate(idxs):\n        plt_idx = i * num_classes + y + 1\n        plt.subplot(samples_per_class, num_classes, plt_idx)\n        plt.imshow(X_train[idx].astype('uint8'))\n        plt.axis('off')\n        if i == 0:\n            plt.title(cls)\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338ac7f",
   "metadata": {
    "id": "e338ac7f",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": "# 为使代码执行更高效，对数据进行子采样\nnum_training = 5000\nmask = list(range(num_training))\nX_train = X_train[mask]\ny_train = y_train[mask]\n\nnum_test = 500\nmask = list(range(num_test))\nX_test = X_test[mask]\ny_test = y_test[mask]\n\n# 将图像数据重新整形为行\nX_train = np.reshape(X_train, (X_train.shape[0], -1))\nX_test = np.reshape(X_test, (X_test.shape[0], -1))\nprint(X_train.shape, X_test.shape)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f708b0b8",
   "metadata": {
    "id": "f708b0b8",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": "from cs231n.classifiers import KNearestNeighbor\n\n# 创建一个 kNN 分类器实例。\n# 请记住，训练一个 kNN 分类器是一个空操作：\n# 分类器只是记住数据，不做进一步处理\nclassifier = KNearestNeighbor()\nclassifier.train(X_train, y_train)"
  },
  {
   "cell_type": "markdown",
   "id": "4a06ac39",
   "metadata": {
    "id": "4a06ac39"
   },
   "source": "现在我们想用 kNN 分类器对测试数据进行分类。回想一下，我们可以将这个过程分为两个步骤：\n\n1. 首先我们必须计算所有测试样本和所有训练样本之间的距离\n2. 给定这些距离后，对于每个测试样本，我们找到 k 个最近的样本并让它们投票决定标签\n\n让我们从计算所有训练和测试样本之间的距离矩阵开始。例如，如果有 **Ntr** 个训练样本和 **Nte** 个测试样本，这个阶段应该产生一个 **Nte × Ntr** 的矩阵，其中每个元素 (i,j) 是第 i 个测试样本和第 j 个训练样本之间的距离。\n\n**注意：对于这个 notebook 中要求的三个距离计算，你不能使用 numpy 提供的 np.linalg.norm() 函数。**\n\n首先，打开 `cs231n/classifiers/k_nearest_neighbor.py` 并实现函数 `compute_distances_two_loops`，该函数使用（非常低效的）双循环来遍历所有（测试，训练）样本对，一次计算一个距离矩阵元素。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769b9914",
   "metadata": {
    "id": "769b9914"
   },
   "outputs": [],
   "source": "# 打开 cs231n/classifiers/k_nearest_neighbor.py 并实现\n# compute_distances_two_loops。\n\n# 测试你的实现：\ndists = classifier.compute_distances_two_loops(X_test)\nprint(dists.shape)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831313d",
   "metadata": {
    "id": "7831313d"
   },
   "outputs": [],
   "source": "# 我们可以可视化距离矩阵：每一行是一个测试样本和它与训练样本的距离\nplt.imshow(dists, interpolation='none')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "0741b588",
   "metadata": {
    "id": "0741b588",
    "tags": [
     "pdf-inline"
    ]
   },
   "source": "**内联问题 1**\n\n注意到距离矩阵中有一些结构化模式，其中一些行或列明显更亮。（注意，在默认的配色方案中，黑色表示低距离，而白色表示高距离。）\n\n- 数据中是什么原因导致了明显亮的行？\n- 什么原因导致了列？\n\n$\\color{blue}{\\\\textit 你的答案：}$ *在此填写。*"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8a0f95",
   "metadata": {
    "id": "3c8a0f95"
   },
   "outputs": [],
   "source": "# 现在实现函数 predict_labels 并运行下面的代码：\n# 我们使用 k = 1（即最近邻）。\ny_test_pred = classifier.predict_labels(dists, k=1)\n\n# 计算并打印正确预测的样本比例\nnum_correct = np.sum(y_test_pred == y_test)\naccuracy = float(num_correct) / num_test\nprint('正确 %d / %d => 准确率: %f' % (num_correct, num_test, accuracy))"
  },
  {
   "cell_type": "markdown",
   "id": "53af3d78",
   "metadata": {
    "id": "53af3d78"
   },
   "source": "你应该期望看到大约 `27%` 的准确率。现在让我们尝试一个更大的 `k`，比如 `k = 5`："
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defdd580",
   "metadata": {
    "id": "defdd580"
   },
   "outputs": [],
   "source": "y_test_pred = classifier.predict_labels(dists, k=5)\nnum_correct = np.sum(y_test_pred == y_test)\naccuracy = float(num_correct) / num_test\nprint('正确 %d / %d => 准确率: %f' % (num_correct, num_test, accuracy))"
  },
  {
   "cell_type": "markdown",
   "id": "7a23ead9",
   "metadata": {
    "id": "7a23ead9"
   },
   "source": "你应该期望看到比 `k = 1` 略好的性能。"
  },
  {
   "cell_type": "markdown",
   "id": "f7437d93",
   "metadata": {
    "id": "f7437d93",
    "tags": [
     "pdf-inline"
    ]
   },
   "source": "**内联问题 2**\n\n我们也可以使用其他距离度量，如 L1 距离。\n对于某个图像 $I_k$ 在位置 $(i,j)$ 处的像素值 $p_{ij}^{(k)}$，\n\n所有图像在所有像素上的平均值是 $$\\mu=\\frac{1}{nhw}\\sum_{k=1}^n\\sum_{i=1}^{h}\\sum_{j=1}^{w}p_{ij}^{(k)}$$\n所有图像在像素 $(i,j)$ 处的平均值是\n$$\\mu_{ij}=\\frac{1}{n}\\sum_{k=1}^np_{ij}^{(k)}.$$\n标准差 $\\sigma$ 和像素级标准差 $\\sigma_{ij}$ 的定义类似。\n\n以下哪些预处理步骤不会改变使用 L1 距离的最近邻分类器的性能？选择所有适用的选项。为了澄清，训练和测试样本都使用相同的方式进行预处理。\n\n1. 减去平均值 $\\mu$ ($\\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\\mu$。)\n2. 减去每个像素的平均值 $\\mu_{ij}$  ($\\tilde{p}_{ij}^{(k)}=p_{ij}^{(k)}-\\mu_{ij}$。)\n3. 减去平均值 $\\mu$ 并除以标准差 $\\sigma$。\n4. 减去像素级平均值 $\\mu_{ij}$ 并除以像素级标准差 $\\sigma_{ij}$。\n5. 旋转数据坐标轴，这意味着将所有图像旋转相同的角度。旋转引起的图像空白区域用相同的像素值填充，不进行插值。\n\n$\\color{blue}{\\\\textit 你的答案：}$\n\n$\\color{blue}{\\\\textit 你的解释：}$"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1f4ec",
   "metadata": {
    "id": "83a1f4ec",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": "# 现在让我们通过使用部分向量化和一个循环来加速距离矩阵计算\n# 实现函数 compute_distances_one_loop 并运行下面的代码：\ndists_one = classifier.compute_distances_one_loop(X_test)\n\n# 为了确保我们的向量化实现是正确的，我们确保它与朴素实现一致。有很多方法可以决定两个矩阵是否相似；其中最简单的是 Frobenius 范数。如果你之前没有见过它，两个矩阵的 Frobenius 范数是所有元素差值平方和的平方根；换句话说，将矩阵重塑为向量并计算它们之间的欧几里得距离。\ndifference = np.linalg.norm(dists - dists_one, ord='fro')\nprint('单循环版本的差异: %f' % (difference, ))\nif difference < 0.001:\n    print('很好！距离矩阵是相同的')\nelse:\n    print('糟糕！距离矩阵不同')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db2c197",
   "metadata": {
    "id": "6db2c197",
    "scrolled": true,
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": "# 现在在 compute_distances_no_loops 内实现完全向量化的版本并运行代码\ndists_two = classifier.compute_distances_no_loops(X_test)\n\n# 检查距离矩阵是否与我们之前计算的一致：\ndifference = np.linalg.norm(dists - dists_two, ord='fro')\nprint('无循环版本的差异: %f' % (difference, ))\nif difference < 0.001:\n    print('很好！距离矩阵是相同的')\nelse:\n    print('糟糕！距离矩阵不同')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f162ac4",
   "metadata": {
    "id": "9f162ac4",
    "tags": [
     "pdf-ignore-input"
    ],
    "test": "no_loop"
   },
   "outputs": [],
   "source": "# 让我们比较实现的运行速度\ndef time_function(f, *args):\n    \"\"\"\n    调用函数 f 和参数，并返回执行所需的时间（以秒为单位）。\n    \"\"\"\n    import time\n    tic = time.time()\n    f(*args)\n    toc = time.time()\n    return toc - tic\n\ntwo_loop_time = time_function(classifier.compute_distances_two_loops, X_test)\nprint('双循环版本用时 %f 秒' % two_loop_time)\n\none_loop_time = time_function(classifier.compute_distances_one_loop, X_test)\nprint('单循环版本用时 %f 秒' % one_loop_time)\n\nno_loop_time = time_function(classifier.compute_distances_no_loops, X_test)\nprint('无循环版本用时 %f 秒' % no_loop_time)\n\n# 你应该看到完全向量化的实现有显著的性能提升！\n\n# 注意：这取决于你使用的机器，\n# 你可能不会看到从两个循环到一个循环时的加速，\n# 甚至可能会看到减速。"
  },
  {
   "cell_type": "markdown",
   "id": "2d453b35",
   "metadata": {
    "id": "2d453b35"
   },
   "source": "### 交叉验证\n\n我们已经实现了 k-近邻分类器，但我们任意设置了 k = 5 的值。现在我们将通过交叉验证来确定这个超参数的最佳值。"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f8efd",
   "metadata": {
    "id": "0f9f8efd",
    "tags": [
     "code"
    ]
   },
   "outputs": [],
   "source": "num_folds = 5\nk_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n\nX_train_folds = []\ny_train_folds = []\n################################################################################\n# TODO:                                                                        #\n# 将训练数据拆分为折叠。拆分后，X_train_folds 和 y_train_folds 应该          #\n# 都是长度为 num_folds 的列表，其中                                         #\n# y_train_folds[i] 是 X_train_folds[i] 中点的标签向量。                     #\n# 提示：查看 numpy array_split 函数。                                        #\n################################################################################\n\n\n# 一个保存我们找到的不同 k 值的准确率的字典。运行交叉验证后，\n# k_to_accuracies[k] 应该是一个长度为 num_folds 的列表，\n# 给出使用该 k 值时找到的不同准确率值。\nk_to_accuracies = {}\n\n\n################################################################################\n# TODO:                                                                        #\n# 执行 k 折交叉验证以找到 k 的最佳值。对于每个可能的 k 值，运行             #\n# k-近邻算法 num_folds 次，在每次中除了一个折叠外的所有折叠用作训练数据，   #\n# 最后一个折叠用作验证集。将所有折叠和所有 k 值的准确率存储在              #\n# k_to_accuracies 字典中。                                                     #\n################################################################################\n\n\n# 打印出计算出的准确率\nfor k in sorted(k_to_accuracies):\n    for accuracy in k_to_accuracies[k]:\n        print('k = %d, 准确率 = %f' % (k, accuracy))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8440adac",
   "metadata": {
    "id": "8440adac",
    "tags": [
     "pdf-ignore-input"
    ]
   },
   "outputs": [],
   "source": "# 绘制原始观测值\nfor k in k_choices:\n    accuracies = k_to_accuracies[k]\n    plt.scatter([k] * len(accuracies), accuracies)\n\n# 绘制带误差线的趋势线，对应标准差\naccuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\naccuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\nplt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\nplt.title('k 的交叉验证')\nplt.xlabel('k')\nplt.ylabel('交叉验证准确率')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a890e022",
   "metadata": {
    "id": "a890e022",
    "test": "cross_validation"
   },
   "outputs": [],
   "source": "# 基于上面的交叉验证结果，选择 k 的最佳值，重新训练分类器\n# 使用所有训练数据，并在测试数据上进行测试。你应该能够获得\n# 超过 28% 的测试准确率。\nbest_k = 1\n\nclassifier = KNearestNeighbor()\nclassifier.train(X_train, y_train)\ny_test_pred = classifier.predict(X_test, k=best_k)\n\n# 计算并显示准确率\nnum_correct = np.sum(y_test_pred == y_test)\naccuracy = float(num_correct) / num_test\nprint('正确 %d / %d => 准确率: %f' % (num_correct, num_test, accuracy))"
  },
  {
   "cell_type": "markdown",
   "id": "6d74b7cc",
   "metadata": {
    "id": "6d74b7cc",
    "tags": [
     "pdf-inline"
    ]
   },
   "source": "**内联问题 3**\n\n关于 $k$-最近邻（$k$-NN）在分类设置中，以下哪些说法对于所有 $k$ 都是正确的？选择所有适用的选项。\n\n1. $k$-NN 分类器的决策边界是线性的。\n2. 1-NN 的训练误差总是小于或等于 5-NN 的训练误差。\n3. 1-NN 的测试误差总是小于 5-NN 的测试误差。\n4. 使用 $k$-NN 分类器分类一个测试样本所需的时间随着训练集的大小而增长。\n5. 以上都不对。\n\n$\\color{blue}{\\\\textit 你的答案：}$\n\n$\\color{blue}{\\\\textit 你的解释：}$"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}